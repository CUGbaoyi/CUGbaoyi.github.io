---
title: "DouFu:A Double Fusion Joint Learning Method for Driving Trajectory Representation"
collection: publications
permalink: /publication/DouFu:A Double Fusion Joint Learning Method for Driving Trajectory Representation
# excerpt: 'Driving trajectory representation learning is of great significance for various location-based services such as driving pattern mining and route recommendation. However, previous representation generation approaches rarely address three challenges: (1) how to represent the intricate semantic intentions of mobility inexpensively, (2) complex and weak spatial\textendash temporal dependencies due to the sparsity and heterogeneity of the trajectory data, and (3) route selection preferences and their correlation to driving behaviour. In this study, we propose a novel multimodal fusion model, DouFu, for trajectory representation joint learning, which applies a multimodal learning and attention fusion module to capture the internal characteristics of trajectories. We first design movement, route, and global features generated from the trajectory data and urban functional zones, and then analyse them with an with the attention encoder or fully connected network. The attention fusion module incorporates route features with movement features to create more effective spatial\textendash temporal embedding. Combined with the global semantic feature, DouFu produced a comprehensive embedding for each trajectory. We evaluated the representations generated by our method and other baseline models on the classification and clustering tasks. The empirical results show that DouFu outperforms other models in most learning algorithms, such as the linear regression and the support vector machines, by more than 10%.'
date: 2022-12-01
venue: 'Knowledge-Based Systems'
# paperurl: 'http://cugbaoyi.github.io/files/wang2022doufu.pdf'
# citation: 'Wang, H., Huang, Z., Zhou, X., Yin, G., **Bao, Y.** & Zhang, Y. (2022). DouFu:A Double Fusion Joint Learning Method for Driving Trajectory Representation. Knowledge-Based Systems, 258(), 110035.'
---
Driving trajectory representation learning is of great significance for various location-based services such as driving pattern mining and route recommendation. However, previous representation generation approaches rarely address three challenges: (1) how to represent the intricate semantic intentions of mobility inexpensively, (2) complex and weak spatial\textendash temporal dependencies due to the sparsity and heterogeneity of the trajectory data, and (3) route selection preferences and their correlation to driving behaviour. In this study, we propose a novel multimodal fusion model, DouFu, for trajectory representation joint learning, which applies a multimodal learning and attention fusion module to capture the internal characteristics of trajectories. We first design movement, route, and global features generated from the trajectory data and urban functional zones, and then analyse them with an with the attention encoder or fully connected network. The attention fusion module incorporates route features with movement features to create more effective spatial\textendash temporal embedding. Combined with the global semantic feature, DouFu produced a comprehensive embedding for each trajectory. We evaluated the representations generated by our method and other baseline models on the classification and clustering tasks. The empirical results show that DouFu outperforms other models in most learning algorithms, such as the linear regression and the support vector machines, by more than 10%.

[DOI](https://doi.org/10.1016/j.knosys.2022.110035)
[Download paper here](http://cugbaoyi.github.io/files/wang2022doufu.pdf)

Recommended citation: Wang, H., Huang, Z., Zhou, X., Yin, G., **Bao, Y.** & Zhang, Y. (2022). DouFu:A Double Fusion Joint Learning Method for Driving Trajectory Representation. Knowledge-Based Systems, 258, 110035.
